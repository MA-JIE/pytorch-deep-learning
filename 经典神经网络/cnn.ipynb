{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的模块\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "#定义一些超参数\n",
    "BATCHSIZE = 100\n",
    "DOWNLOAD_MNIST = False\n",
    "EPOCHES=20\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义相关模型结构：CNNNet, LeNet, VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 16, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=36, kernel_size=3,stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #36 x 6 x 6\n",
    "        self.fc1 = nn.Linear(1296,128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "    def forward(self,x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "#         print(\"x's shape is {}\".format(x.shape))\n",
    "        x = x.view(-1,36*6*6)\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 36, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.aap = nn.AdaptiveAvgPool2d(1)#output 样本数 x 36 x 1 x 1\n",
    "        self.fc3 = nn.Linear(36, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "#         print(\"brfore aap: {}\".format(x.shape))\n",
    "        x = self.aap(x)\n",
    "#         print(\"after aap: {}\".format(x.shape))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "#         print(\"after view, shape :{}\".format(x.shape))\n",
    "#         print(\"after view, size():{}\".format(x.size()))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512,10)\n",
    "    def forward(self,x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                          nn.BatchNorm2d(x),\n",
    "                          nn.ReLU(inplace=True)]\n",
    "                #nn.ReLu在构建网络结构时加入，inplace = true可节省空间，F.relu()在forward函数中用\n",
    "                in_channels = x\n",
    "            layers += [nn.AvgPool2d(kernel_size = 1,stride = 1)]\n",
    "        return nn.Sequential(*layers)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#导入数据，若已下载本地，设download=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Preparing data..\n",
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#data\n",
    "print('==>Preparing data..')\n",
    "#transform对数据源进行预处理\n",
    "transform_train = transforms.Compose([\n",
    "    #随机裁剪图片\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    #图像随机水平翻转\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #将一个取值范围是[0,255]的PIL.Image转换成Tensor\n",
    "    transforms.ToTensor(),\n",
    "    #标准化，减均值，除以标准差\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root= '../../pytorch-data/data', train=True,download=False,transform=transform_train)\n",
    "#num_workers一般经验值为自己电脑的cpu核心数\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = '../../pytorch-data/data', train=False,download=False,transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','frog','horse','ship','truck')\n",
    "\n",
    "#Model\n",
    "print('==> Building model..')\n",
    "net1 = CNNNet()\n",
    "net2 = Net()\n",
    "net3 = LeNet()\n",
    "net4 = VGG('VGG16')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0集成模型的正确率45.99\n",
      "模型0正确率为：43.62\n",
      "模型1正确率为：38.92\n",
      "模型2正确率为：42.18\n",
      "epoch:1集成模型的正确率51.65\n",
      "模型0正确率为：46.77\n",
      "模型1正确率为：44.7\n",
      "模型2正确率为：49.89\n",
      "epoch:2集成模型的正确率56.48\n",
      "模型0正确率为：50.33\n",
      "模型1正确率为：47.31\n",
      "模型2正确率为：52.95\n",
      "epoch:3集成模型的正确率59.3\n",
      "模型0正确率为：52.14\n",
      "模型1正确率为：49.47\n",
      "模型2正确率为：56.17\n",
      "epoch:4集成模型的正确率61.19\n",
      "模型0正确率为：53.01\n",
      "模型1正确率为：52.16\n",
      "模型2正确率为：57.62\n",
      "epoch:5集成模型的正确率61.51\n",
      "模型0正确率为：54.23\n",
      "模型1正确率为：53.09\n",
      "模型2正确率为：58.24\n",
      "epoch:6集成模型的正确率63.28\n",
      "模型0正确率为：55.26\n",
      "模型1正确率为：54.32\n",
      "模型2正确率为：60.69\n",
      "epoch:7集成模型的正确率63.62\n",
      "模型0正确率为：55.96\n",
      "模型1正确率为：54.89\n",
      "模型2正确率为：60.85\n",
      "epoch:8集成模型的正确率64.65\n",
      "模型0正确率为：55.9\n",
      "模型1正确率为：55.02\n",
      "模型2正确率为：60.5\n",
      "epoch:9集成模型的正确率65.43\n",
      "模型0正确率为：56.62\n",
      "模型1正确率为：56.47\n",
      "模型2正确率为：61.87\n",
      "epoch:10集成模型的正确率65.62\n",
      "模型0正确率为：57.18\n",
      "模型1正确率为：56.71\n",
      "模型2正确率为：63.03\n",
      "epoch:11集成模型的正确率67.16\n",
      "模型0正确率为：57.75\n",
      "模型1正确率为：57.68\n",
      "模型2正确率为：62.2\n",
      "epoch:12集成模型的正确率66.52\n",
      "模型0正确率为：57.22\n",
      "模型1正确率为：59.24\n",
      "模型2正确率为：62.93\n",
      "epoch:13集成模型的正确率67.37\n",
      "模型0正确率为：57.67\n",
      "模型1正确率为：59.92\n",
      "模型2正确率为：63.43\n",
      "epoch:14集成模型的正确率67.86\n",
      "模型0正确率为：58.18\n",
      "模型1正确率为：59.27\n",
      "模型2正确率为：64.14\n",
      "epoch:15集成模型的正确率67.86\n",
      "模型0正确率为：58.51\n",
      "模型1正确率为：59.03\n",
      "模型2正确率为：63.95\n",
      "epoch:16集成模型的正确率67.25\n",
      "模型0正确率为：58.14\n",
      "模型1正确率为：59.39\n",
      "模型2正确率为：63.83\n",
      "epoch:17集成模型的正确率68.53\n",
      "模型0正确率为：58.09\n",
      "模型1正确率为：59.48\n",
      "模型2正确率为：63.74\n",
      "epoch:18集成模型的正确率69.02\n",
      "模型0正确率为：59.11\n",
      "模型1正确率为：61.24\n",
      "模型2正确率为：64.68\n",
      "epoch:19集成模型的正确率69.05\n",
      "模型0正确率为：59.11\n",
      "模型1正确率为：61.91\n",
      "模型2正确率为：65.03\n"
     ]
    }
   ],
   "source": [
    "#将三个网络模型放在一个列表里,并将模型加载到指定设备上\n",
    "mlps = [net1.to(device), net2.to(device), net3.to(device)]\n",
    "optimizer = torch.optim.Adam([{\"params\":mlp.parameters()} for mlp in mlps], lr = LR)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "\n",
    "for ep in range(EPOCHES):\n",
    "    for img, label in trainloader:\n",
    "        img,label = img.to(device), label.to(device)\n",
    "        optimizer.zero_grad() #10个网络清除梯度\n",
    "        for mlp in mlps:\n",
    "            mlp.train()\n",
    "            out = mlp(img)\n",
    "            loss = loss_function(out,label)\n",
    "            loss.backward()#获取梯度\n",
    "        optimizer.step()\n",
    "    pre = []\n",
    "    vote_correct=0\n",
    "    #[0,0,0]\n",
    "    mlps_correct=[0 for i in range(len(mlps))]\n",
    "    for img, label in testloader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        for i, mlp in enumerate(mlps):\n",
    "            mlp.eval()\n",
    "            out=mlp(img)\n",
    "            _,prediction=torch.max(out,1) #按行取最大值,索引\n",
    "            pre_num=prediction.cpu().numpy()\n",
    "            mlps_correct[i] += (pre_num==label.cpu().numpy()).sum()\n",
    "            \n",
    "            pre.append(pre_num)\n",
    "        arr = np.array(pre)\n",
    "        pre.clear()\n",
    "        #Counter统计字符出现的次数\n",
    "        result = [Counter(arr[:,i]).most_common(1)[0][0] for i in range(BATCHSIZE)]\n",
    "        vote_correct += (result == label.cpu().numpy()).sum()\n",
    "    print(\"epoch:\" + str(ep) + \"集成模型的正确率\" + str(vote_correct/len(testloader)))\n",
    "    for inx, correct in enumerate(mlps_correct):\n",
    "        print(\"模型\" + str(inx) + \"正确率为：\" + str(correct/len(testloader)))\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16模型迭代0次的正确率为：51.25\n",
      "VGG16模型迭代1次的正确率为：59.4\n",
      "VGG16模型迭代2次的正确率为：73.09\n",
      "VGG16模型迭代3次的正确率为：78.24\n",
      "VGG16模型迭代4次的正确率为：76.22\n",
      "VGG16模型迭代5次的正确率为：79.81\n",
      "VGG16模型迭代6次的正确率为：83.47\n",
      "VGG16模型迭代7次的正确率为：80.76\n",
      "VGG16模型迭代8次的正确率为：84.34\n",
      "VGG16模型迭代9次的正确率为：85.4\n",
      "VGG16模型迭代10次的正确率为：85.09\n",
      "VGG16模型迭代11次的正确率为：86.36\n",
      "VGG16模型迭代12次的正确率为：87.63\n",
      "VGG16模型迭代13次的正确率为：86.61\n",
      "VGG16模型迭代14次的正确率为：87.87\n",
      "VGG16模型迭代15次的正确率为：88.57\n",
      "VGG16模型迭代16次的正确率为：88.49\n",
      "VGG16模型迭代17次的正确率为：88.89\n",
      "VGG16模型迭代18次的正确率为：87.96\n",
      "VGG16模型迭代19次的正确率为：88.95\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save() missing 2 required positional arguments: 'obj' and 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1f7f77d204b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoreect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmlps_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VGG16模型迭代\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"次的正确率为：\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoreect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: save() missing 2 required positional arguments: 'obj' and 'f'"
     ]
    }
   ],
   "source": [
    "mlps=[net4.to(device)]\n",
    "\n",
    "optimizer=torch.optim.Adam([{\"params\":mlp.parameters()} for mlp in mlps],lr=LR)\n",
    "  \n",
    "loss_function=nn.CrossEntropyLoss()\n",
    " \n",
    "for ep in range(EPOCHES):\n",
    "    for img,label in trainloader:\n",
    "        img,label=img.to(device),label.to(device)\n",
    "        optimizer.zero_grad()#10个网络清除梯度\n",
    "        for mlp in mlps:\n",
    "            mlp.train()\n",
    "            out=mlp(img)\n",
    "            loss=loss_function(out,label)\n",
    "            loss.backward()#网络们获得梯度\n",
    "        optimizer.step()\n",
    " \n",
    "    pre=[]\n",
    "    vote_correct=0\n",
    "    mlps_correct=[0 for i in range(len(mlps))]\n",
    "    for img,label in testloader:\n",
    "        img,label=img.to(device),label.to(device)\n",
    "        for i, mlp in  enumerate( mlps):\n",
    "            mlp.eval()\n",
    "            out=mlp(img)\n",
    " \n",
    "            _,prediction=torch.max(out,1) #按行取最大值\n",
    "            pre_num=prediction.cpu().numpy()\n",
    "            mlps_correct[i]+=(pre_num==label.cpu().numpy()).sum()\n",
    " \n",
    "            pre.append(pre_num)\n",
    "        arr=np.array(pre)\n",
    "        pre.clear()\n",
    "        result=[Counter(arr[:,i]).most_common(1)[0][0] for i in range(BATCHSIZE)]\n",
    "        vote_correct+=(result == label.cpu().numpy()).sum()\n",
    "    #print(\"epoch:\" + str(ep)+\"集成模型的正确率\"+str(vote_correct/len(testloader)))\n",
    " \n",
    "    for idx, coreect in enumerate( mlps_correct):\n",
    "        print(\"VGG16模型迭代\"+str(ep)+\"次的正确率为：\"+str(coreect/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
