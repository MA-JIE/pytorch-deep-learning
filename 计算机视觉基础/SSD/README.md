single shot multibox detection(SSD)
==================================
单发多框检测(多尺度的目标检测模型)
----------------
paper: https://arxiv.org/pdf/1512.02325.pdf <br>
该目标检测模型基于边界框，锚框，多尺度检测等概念构建而成.<br>
[锚框&&多尺度检测](../README.md)<br>
设计图如下,主要由一个基础网络块和若干多尺度特征块串联而成:<br>
![SSD](https://github.com/MA-JIE/pytorch-deep-learning/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/SSD/img/SSD1.png)<br>
单发多框检测模型一共包含5个模块,每个模块输出的特征图既用来生成锚框,又用来预测这些锚框的类别和偏移量。第一模块为基础网络块,第二模块至第四模块为高和宽减半块,第五模块使用全局最大池化层将高和宽降到1。因此第二模块至第五模块均为下图中的多尺度特征块. <br>
![SSD](https://github.com/MA-JIE/pytorch-deep-learning/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/SSD/img/SSD.png)<br>
基础网络块用来从原始图像中抽取特征，一般会选择常用的深度卷积网络.我们可以设计基础网络,使它输出的高和宽较大.这样一来,基于该特征图生成的锚框数量较多,可以用来检测尺寸较小的目标.接下来的每个多尺度特征块将上一层提供的特征图的高和宽缩小(如减半),并使特征图中每个单元在输入图像上的感受野变得更广阔。如此一来,上图中越靠近顶部的多尺度特征块输出的特征图越小,故而基于特征图生成的锚框也越少,加之特征图中每个单元感受野越大,因此更适合检测尺寸较大的目标。由于单发多框检测基于基础网络块和各个多尺度特征块生成不同数量和不同大小的锚框,并通过预测锚框的类别和偏移量(即预测边界框)检测不同大小的目标,因此单发多框检测是一个多尺度的目标检测模型. <br>
# 类别预测层
设目标的类别个数为q。每个锚框的类别个数将是q + 1,其中类别0表示锚框只包含背景。在某个尺度下,设特征图的高和宽分别为h和w,如果以其中每个单元为中心生成a个锚框,那么我们需要对hwa个锚框进行分类。如果使用全连接层作为输出,很容易导致模型参数过多。参考网络中的网络(NiN)使用卷积层的通道来输出类别预测的方法,单发多框检测采用同样的方法来降低模型复杂度。具体来说,类别预测层使用一个保持输入高和宽的卷积层。这样一来,输出和输入在特征图宽和高上的空间坐标一一对应。考虑输出和输入同一空间坐标(x, y):输出特征图上(x, y)坐标的通道里包含了以输入特征图(x, y)坐标为中心生成的所有锚框的类别预测。因此输出通道数为a(q + 1),其中索引为i(q + 1) + j(0 ≤ j ≤ q)的通道代表了索引为i的锚框有关类别索引为j的预测.<br>

# 边界框预测层
边界框预测层的设计与类别预测层的设计类似。唯一不同的是,这里需要为每个锚框预测4个偏移量,而不是q + 1个类别. <br>

# 连接多尺度的预测
前面提到,单发多框检测根据多个尺度下的特征图生成锚框并预测类别和偏移量.由于每个尺度上特征图的形状或以同一单元为中心生成的锚框个数都可能不同,因此不同尺度的预测输出形状可能不同. 我们对同一批量数据构造两个不同尺度下的特征图Y1和Y2,其中Y2相对于Y1来说高和宽分别减半.以类别预测为例,假设以Y1和Y2特征图中每个单元生成的锚框个数分别是5和3,当目标类别个数为10时,类别预测输出的通道数分别为5×(10+1) = 55和3×(10+1) = 33.预测输出的格式为(批量大小, 通道数, 高, 宽).可以看到,除了批量大小外,其他维度大小均不一样.我们需要将它们变形成统一的格式并将多尺度的预测连结,从而让后续计算更简单. <br>
我们首先将通道维移到最后一维。因为不同尺度下批量大小仍保持不变,我们可以将预测结果转成二维的(批量大小, 高×宽×通道数)的格式,以方便之后在维度1上的连结. <br>

# 高和宽减半块
为了在多尺度检测目标,
下面定义高和宽减半块down_sample_blk。它串联了两个填充为1的3×3卷积层和步幅为2的2 × 2最大池化层。我们知道,填充为1的3 × 3卷积层不改变特征图的形状,而后面的池化层则直接将特征图的高和宽减半。由于1 × 2 + (3 − 1) + (3 − 1) = 6,输出特征图中每个单元在输入特征图上的感受野形状为6 × 6。可以看出,高和宽减半块使输出特征图中每个单元的感受野变得更广阔. <br>
# 基础网络块
基础网络块用来从原始图像中抽取特征. <br>

# 损失函数与评价函数
目标检测有两个损失:一是有关锚框类别的损失,我们可以重用之前图像分类问题里一直使用的交叉熵损失函数;二是有关正类锚框偏移量的损失。预测偏移量是一个回归问题,但这里不使用前面介绍过的平方损失,而使用L 1 范数损失,即预测值与真实值之间差的绝对值。掩码变量bbox_masks令负类锚框和填充锚框不参与损失的计算。最后,我们将有关锚框类别和偏移量的损失相加得到模型的最终损失函数. <br>
# 训练模型
在训练模型时,我们需要在模型的前向计算过程中生成多尺度的锚框anchors,并为每个锚框预测类别cls_preds和偏移量bbox_preds。之后,我们根据标签信息Y为生成的每个锚框标注类别cls_labels和偏移量bbox_labels。最后,我们根据类别和偏移量的预测和标注值计算损失函数. <br>
